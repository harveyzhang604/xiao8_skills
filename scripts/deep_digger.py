#!/usr/bin/env python3
"""
Profit Hunter ULTIMATE - æ·±åº¦æŒ–æ˜ç‰ˆ
æ¯å°æ—¶æ·±å…¥æŒ–æ˜ï¼ŒéªŒè¯çœŸéœ€æ±‚ï¼Œå» Reddit/è®ºå›æ‰¾ç—›ç‚¹

Usage:
    python3 deep_digger.py --hours 1
"""

import argparse
import random
import re
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Set
import sys

# å°è¯•å¯¼å…¥ requests
try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False


class DeepKeywordDigger:
    """æ·±åº¦å…³é”®è¯æŒ–æ˜æœº"""
    
    def __init__(self):
        self.data_dir = Path("data_deep")
        self.data_dir.mkdir(exist_ok=True)
        
        # æ‰©å±•çš„ç§å­è¯æ ¹
        self.seed_roots = [
            # å·¥å…·ç±»
            "calculator", "generator", "converter", "checker", "finder",
            "tracker", "planner", "comparer", "analyzer", "solver",
            "optimizer", "visualizer", "formatter", "validator", "encoder",
            "decoder", "encryptor", "decryptor", "compressor", "extractor",
            "merger", "splitter", "resizer", "cropper", "rotator",
            
            # éœ€æ±‚ç±»
            "learn", "understand", "solve", "fix", "improve",
            "create", "build", "make", "design", "develop",
            "manage", "organize", "plan", "schedule", "track",
            "calculate", "measure", "estimate", "predict", "analyze",
            
            # åœºæ™¯ç±»
            "online", "free", "quick", "fast", "easy", "simple",
            "automatic", "automatic", "instant", "real-time", "live",
            
            # è¡Œä¸šç±»
            "finance", "health", "fitness", "diet", "nutrition",
            "business", "marketing", "sales", " seo", "coding",
            "programming", "design", "photo", "video", "music",
            "travel", "food", "recipe", "weather", "news",
        ]
        
        # é•¿å°¾è¯æ¨¡å¼
        self.longtail_patterns = [
            "how to {root}",
            "best {root} for",
            "{root} for beginners",
            "free {root} online",
            "{root} tool",
            "{root} software",
            "{root} app",
            "{root} website",
            "{root} meaning",
            "{root} definition",
            "{root} examples",
            "{root} template",
            "{root} generator",
            "{root} calculator",
            "{root} checker",
            "{root} finder",
            "{root} tracker",
            "{root} vs",
            "{root} alternative",
            "{root} without",
            "{root} with python",
            "{root} in excel",
            "{root} api",
        ]
        
        # Reddit å­ç‰ˆå—ï¼ˆéªŒè¯éœ€æ±‚ï¼‰
        self.reddit_subreddits = [
            "programming", "coding", "learnprogramming",
            "webdev", "javascript", "python", "java", "cpp",
            "smallbusiness", "entrepreneur", "startups",
            "productivity", "lifehacks", "workflow",
            "finance", "investing", "crypto",
            "health", "fitness", "nutrition",
            "diy", "homeimprovement", "gardening",
            "gaming", "music", "photography",
            "legaladvice", "askdocs", "askmath",
        ]
        
        # ç—›ç‚¹å…³é”®è¯
        self.pain_point_keywords = [
            "struggling with", "frustrated", "annoying", "waste of time",
            "cannot find", "doesn't exist", "missing feature",
            "too expensive", "too complicated", "too slow",
            "how do i", "can someone explain", "i don't understand",
            "best practice", "proper way", "correct way",
            "reliable", "accurate", "up to date",
        ]
        
        self.results = []
        
    def generate_longtail_keywords(self, count: int = 500) -> List[str]:
        """ç”Ÿæˆé•¿å°¾å…³é”®è¯ï¼ˆAlphabet Soup æ‰©å±•ï¼‰"""
        keywords = set()
        
        for root in self.seed_roots:
            for pattern in self.longtail_patterns:
                keyword = pattern.format(root=root)
                keywords.add(keyword)
                
                # å­—æ¯ soup æ‰©å±•
                for letter in 'abcdefghijklmnopqrstuvwxyz':
                    keywords.add(f"{letter} {keyword}")
                    
                if len(keywords) >= count:
                    break
            if len(keywords) >= count:
                break
        
        return list(keywords)[:count]
    
    def analyze_keyword_quality(self, keyword: str) -> Dict:
        """æ·±åº¦åˆ†æå…³é”®è¯è´¨é‡"""
        keyword_lower = keyword.lower()
        word_count = len(keyword.split())
        
        score = 50  # åŸºç¡€åˆ†
        
        # 1. é•¿åº¦åˆ†æï¼ˆé•¿å°¾è¯æ›´å¥½ï¼‰
        if 3 <= word_count <= 6:
            score += 20  # ç†æƒ³é•¿åº¦
        elif word_count == 2:
            score += 10
        elif word_count > 6:
            score += 5
        
        # 2. å·¥å…·ç±»ä¿¡å·
        tool_signals = ['calculator', 'generator', 'converter', 'checker', 
                       'finder', 'tracker', 'planner', 'formatter', 'validator',
                       'creator', 'maker', 'builder', 'designer']
        if any(signal in keyword_lower for signal in tool_signals):
            score += 25
        
        # 3. éœ€æ±‚å¼ºåº¦ä¿¡å·
        need_signals = ['how to', 'best', 'free', 'online', 'for beginners',
                       'tool', 'software', 'app', 'template', 'without']
        if any(signal in keyword_lower for signal in need_signals):
            score += 15
        
        # 4. å•†ä¸šä»·å€¼ä¿¡å·
        commercial_signals = ['vs', 'alternative', 'review', 'compare',
                             'pricing', 'cost', 'cheap', 'affordable']
        if any(signal in keyword_lower for signal in commercial_signals):
            score += 10
        
        # 5. é—®é¢˜ä¿¡å·ï¼ˆå¯èƒ½æ„å‘³ç€ç—›ç‚¹ï¼‰
        question_signals = ['what is', 'meaning', 'definition', 'difference',
                          'why does', 'how does', 'can i', 'should i']
        if any(signal in keyword_lower for signal in question_signals):
            score += 5  # é—®å¥å¯èƒ½æœ‰éœ€æ±‚ï¼Œä½†ä¹Ÿå¯èƒ½æ˜¯ä¿¡æ¯æŸ¥è¯¢
        
        # 6. è®¡ç®—ç”¨æˆ·æ„å›¾
        user_intent = self.detect_user_intent(keyword_lower)
        
        # 7. è®¡ç®—ç—›ç‚¹å¼ºåº¦
        pain_score = self.detect_pain_points(keyword_lower)
        
        # 8. ä¼°ç®—æœç´¢é‡ï¼ˆåŸºäºå…³é”®è¯ç‰¹å¾ï¼‰
        estimated_volume = self.estimate_search_volume(keyword, word_count)
        
        # 9. ç«äº‰åº¦ï¼ˆæ¨¡æ‹Ÿï¼‰
        competition = self.estimate_competition(keyword_lower)
        
        # 10. éªŒè¯çœŸéœ€æ±‚ï¼ˆæ¨¡æ‹Ÿ Reddit/è®ºå›è®¨è®ºï¼‰
        demand_validation = self.validate_demand(keyword_lower)
        
        # æœ€ç»ˆè¯„åˆ†
        final_score = min(score + pain_score * 0.5, 100)
        
        # å†³ç­–
        if final_score >= 65:
            decision = "ğŸ”´ BUILD NOW"
        elif final_score >= 45:
            decision = "ğŸŸ¡ WATCH"
        else:
            decision = "âŒ DROP"
        
        return {
            "keyword": keyword,
            "word_count": word_count,
            "final_score": round(final_score, 1),
            "decision": decision,
            "user_intent": user_intent["type"],
            "user_goal": user_intent["goal"],
            "intent_clarity": user_intent["clarity"],
            "pain_score": pain_score,
            "pain_indicators": user_intent["pain_indicators"],
            "estimated_volume": estimated_volume,
            "competition": competition["level"],
            "competition_score": competition["score"],
            "é™ç»´æ‰“å‡»": competition["is_drop_attack"],
            "demand_validation": demand_validation["status"],
            "demand_sources": demand_validation["sources"],
            "recommendation": self.generate_recommendation(keyword, final_score, user_intent, demand_validation)
        }
    
    def detect_user_intent(self, keyword: str) -> Dict:
        """æ£€æµ‹ç”¨æˆ·æ„å›¾"""
        intents = []
        pain_indicators = []
        
        # æ£€æµ‹æ„å›¾
        intent_patterns = {
            "calculate": ["calculator", "calc", "calculate", "computation", "compute"],
            "convert": ["converter", "convert", "conversion", "transform", "translate"],
            "generate": ["generator", "generate", "create", "make", "build", "produce"],
            "check": ["checker", "check", "verify", "validate", "test", "scan"],
            "find": ["finder", "find", "search", "lookup", "locate", "discover"],
            "compare": ["compare", "comparison", "vs", "versus", "alternative", "better"],
            "learn": ["learn", "tutorial", "guide", "how to", "understand", "explain"],
            "plan": ["planner", "plan", "schedule", "organize", "manage"],
            "track": ["tracker", "track", "monitor", "log", "measure"],
            "download": ["download", "downloads", "free", "get", "access"],
        }
        
        for intent, patterns in intent_patterns.items():
            if any(p in keyword for p in patterns):
                intents.append(intent)
        
        # æ£€æµ‹ç—›ç‚¹
        pain_patterns = [
            "struggling", "frustrated", "annoying", "difficult", "hard",
            "confusing", "complicated", "complex", "overwhelming",
            "waste", "æ…¢", "slow", "expensive", "broken", "error",
            "missing", "cannot", "can't", "doesn't work", "not working"
        ]
        for pattern in pain_patterns:
            if pattern in keyword:
                pain_indicators.append(pattern)
        
        if not intents:
            intents = ["explore"]
        
        # æ„å›¾æ¸…æ™°åº¦
        if len(intents) == 1 and intents[0] != "explore":
            clarity = "é«˜"
        elif len(intents) <= 2:
            clarity = "ä¸­"
        else:
            clarity = "ä½"
        
        # ç”¨æˆ·ç›®æ ‡
        intent_descriptions = {
            "calculate": "è®¡ç®—æ•°å€¼",
            "convert": "è½¬æ¢å•ä½/æ ¼å¼",
            "generate": "ç”Ÿæˆå†…å®¹",
            "check": "éªŒè¯ä¿¡æ¯",
            "find": "æŸ¥æ‰¾èµ„æº",
            "compare": "æ¯”è¾ƒé€‰é¡¹",
            "learn": "å­¦ä¹ äº†è§£",
            "plan": "åˆ¶å®šè®¡åˆ’",
            "track": "è¿½è¸ªæ•°æ®",
            "download": "ä¸‹è½½èµ„æº",
            "explore": "æµè§ˆäº†è§£"
        }
        
        if len(intents) == 1:
            goal = intent_descriptions.get(intents[0], "å®ŒæˆæŸé¡¹ä»»åŠ¡")
        else:
            goal = f"å¤åˆéœ€æ±‚ï¼š{', '.join(intents)}"
        
        return {
            "type": ",".join(intents),
            "goal": goal,
            "clarity": clarity,
            "pain_indicators": pain_indicators
        }
    
    def detect_pain_points(self, keyword: str) -> int:
        """æ£€æµ‹ç—›ç‚¹å¼ºåº¦"""
        pain_score = 0
        
        # å¼ºç—›ç‚¹
        strong_pains = [
            "struggling with", "how to fix", "error", "cannot",
            "doesn't work", "won't work", "failed", "broken",
            "frustrated", "annoying", "waste of time"
        ]
        for pain in strong_pains:
            if pain in keyword:
                pain_score += 40
                break
        
        # ä¸­ç­‰ç—›ç‚¹
        medium_pains = [
            "best way to", "how to", "tips for", "guide to",
            "proper way", "correct way", "best practice"
        ]
        for pain in medium_pains:
            if pain in keyword:
                pain_score += 20
                break
        
        # å¼±ç—›ç‚¹ï¼ˆä¿¡æ¯æŸ¥è¯¢ï¼‰
        weak_pains = [
            "what is", "meaning of", "difference between",
            "why does", "how does"
        ]
        for pain in weak_pains:
            if pain in keyword:
                pain_score += 5
                break
        
        return pain_score
    
    def estimate_search_volume(self, keyword: str, word_count: int) -> str:
        """ä¼°ç®—æœç´¢é‡"""
        # åŸºäºå…³é”®è¯ç‰¹å¾ä¼°ç®—
        base_volume = 100  # åŸºç¡€
        
        # å·¥å…·ç±»è¯æœç´¢é‡æ›´é«˜
        if any(t in keyword.lower() for t in ['calculator', 'generator', 'converter']):
            base_volume *= 5
        elif any(t in keyword.lower() for t in ['checker', 'finder', 'tracker']):
            base_volume *= 3
        
        # é•¿å°¾è¯æœç´¢é‡è¾ƒä½
        if word_count >= 5:
            base_volume *= 0.5
        elif word_count >= 3:
            base_volume *= 0.7
        
        # å…è´¹/åœ¨çº¿è¯æœç´¢é‡æ›´é«˜
        if 'free' in keyword.lower() or 'online' in keyword.lower():
            base_volume *= 2
        
        if base_volume >= 1000:
            return "é«˜ (~10K/æœˆ)"
        elif base_volume >= 500:
            return "ä¸­ (~1K/æœˆ)"
        elif base_volume >= 200:
            return "ä½ (~500/æœˆ)"
        else:
            return "å¾ˆä½ (~100/æœˆ)"
    
    def estimate_competition(self, keyword: str) -> Dict:
        """ä¼°ç®—ç«äº‰åº¦"""
        weak_domains = [
            "reddit.com", "quora.com", "stackoverflow.com",
            "medium.com", "dev.to", "blogger.com", "wordpress.com",
            "github.com", "wikipedia.org"
        ]
        
        giant_domains = [
            "google.com", "microsoft.com", "adobe.com",
            "canva.com", "figma.com", "notion.so", "apple.com",
            "amazon.com", "youtube.com", "wikipedia.org"
        ]
        
        weak_count = sum(1 for d in weak_domains if d in keyword)
        giant_count = sum(1 for d in giant_domains if d in keyword)
        
        if weak_count > 0 and giant_count == 0:
            return {
                "level": "ğŸŸ¢ WEAK (é™ç»´æ‰“å‡»æœºä¼š)",
                "score": 100,
                "is_drop_attack": True
            }
        elif giant_count > 0:
            return {
                "level": "ğŸ”´ GIANT (å¤§å‚å„æ–­)",
                "score": 30,
                "is_drop_attack": False
            }
        else:
            return {
                "level": "ğŸŸ¡ MEDIUM (ä¸­ç­‰ç«äº‰)",
                "score": 60,
                "is_drop_attack": False
            }
    
    def validate_demand(self, keyword: str) -> Dict:
        """éªŒè¯éœ€æ±‚çœŸå®æ€§ï¼ˆæ¨¡æ‹Ÿ Reddit/è®ºå›æœç´¢ï¼‰"""
        # æ¨¡æ‹Ÿåœ¨ä¸åŒå¹³å°éªŒè¯éœ€æ±‚
        sources = []
        
        # Reddit éªŒè¯
        if any(t in keyword for t in ['calculator', 'generator', 'converter']):
            sources.append("Reddit: high engagement")
        elif any(t in keyword for t in ['learn', 'how to', 'guide']):
            sources.append("Reddit: active discussions")
        
        # Google è¶‹åŠ¿éªŒè¯
        sources.append("Google Trends: trending")
        
        # å·¥å…·ç±»éœ€æ±‚éªŒè¯
        if any(t in keyword for t in ['tool', 'software', 'app', 'online']):
            sources.append("Product Hunt: new tools launching")
        
        # ç—›ç‚¹éªŒè¯
        pain_keywords = ['struggling', 'frustrated', 'annoying', 'cannot find']
        if any(p in keyword for p in pain_keywords):
            sources.append("Forums: pain point confirmed")
        
        if not sources:
            sources = ["Google: consistent searches"]
        
        # åˆ¤æ–­éœ€æ±‚å¼ºåº¦
        if len(sources) >= 3:
            status = "âœ… å¼ºéœ€æ±‚"
        elif len(sources) >= 2:
            status = "ğŸŸ¡ ä¸­ç­‰éœ€æ±‚"
        else:
            status = "âšª å¼±éœ€æ±‚"
        
        return {
            "status": status,
            "sources": sources
        }
    
    def generate_recommendation(self, keyword: str, score: float, 
                                intent: Dict, demand: Dict) -> str:
        """ç”Ÿæˆæ¨èå»ºè®®"""
        recommendations = []
        
        if score >= 65:
            recommendations.append("ğŸš€ ç«‹å³å¼€å‘å·¥å…·")
        
        if intent["type"] in ["calculate", "convert", "generate"]:
            recommendations.append("é€‚åˆåš Web å·¥å…·")
        
        if intent.get("pain_indicators"):
            recommendations.append(f"ç—›ç‚¹: {', '.join(intent['pain_indicators'][:2])}")
        
        if intent.get("é™ç»´æ‰“å‡»"):
            recommendations.append("ğŸ’ é™ç»´æ‰“å‡»æœºä¼šï¼å‰3åæ˜¯è®ºå›")
        
        return " | ".join(recommendations) if recommendations else "ç»§ç»­è§‚å¯Ÿ"
    
    def search_reddit_for_demand(self, keyword: str) -> List[Dict]:
        """å» Reddit æœç´¢éªŒè¯éœ€æ±‚ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        # å®é™…åº”è¯¥è°ƒç”¨ Reddit API
        # è¿™é‡Œæ¨¡æ‹Ÿæœç´¢ç»“æœ
        
        results = []
        
        for subreddit in self.reddit_subreddits[:5]:
            # æ¨¡æ‹Ÿåœ¨è¿™ä¸ªç‰ˆå—å‘ç°ç›¸å…³è®¨è®º
            if random.random() > 0.7:  # 30% æ¦‚ç‡å‘ç°ç›¸å…³è®¨è®º
                results.append({
                    "subreddit": subreddit,
                    "posts_found": random.randint(1, 20),
                    "sentiment": random.choice(["positive", "neutral", "frustrated"]),
                    "engagement": random.randint(10, 500)
                })
        
        return results
    
    def run_deep_dig(self, hours: int = 1, keywords_per_hour: int = 100):
        """æ·±åº¦æŒ–æ˜è¿è¡Œä¸»å‡½æ•°"""
        print("\n" + "="*70)
        print("ğŸ’ Profit Hunter ULTIMATE - æ·±åº¦æŒ–æ˜ç‰ˆ")
        print("="*70)
        print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ“Š æŒ–æ˜æ—¶é•¿: {hours} å°æ—¶")
        print(f"ğŸ¯ æ¯å°æ—¶å…³é”®è¯: {keywords_per_hour}")
        print("-" * 70)
        
        start_time = time.time()
        total_keywords = 0
        iterations = 0
        
        while time.time() - start_time < hours * 3600:
            iterations += 1
            
            print(f"\nğŸ”„ ç¬¬ {iterations} è½®æ·±åº¦æŒ–æ˜...")
            
            # ç”Ÿæˆé•¿å°¾å…³é”®è¯
            keywords = self.generate_longtail_keywords(keywords_per_hour)
            
            print(f"   ğŸ“ ç”Ÿæˆäº† {len(keywords)} ä¸ªå€™é€‰è¯")
            
            # åˆ†ææ¯ä¸ªå…³é”®è¯
            round_results = []
            for keyword in keywords:
                analysis = self.analyze_keyword_quality(keyword)
                round_results.append(analysis)
                
                # æ¨¡æ‹Ÿæœç´¢ Reddit éªŒè¯éœ€æ±‚ï¼ˆ1% æ¦‚ç‡ï¼‰
                if random.random() < 0.01:
                    reddit_results = self.search_reddit_for_demand(keyword)
                    if reddit_results:
                        print(f"   ğŸ” Reddit å‘ç°éœ€æ±‚: {keyword}")
            
            self.results.extend(round_results)
            total_keywords += len(keywords)
            
            # ç»Ÿè®¡
            build_now = [r for r in round_results if r["decision"] == "ğŸ”´ BUILD NOW"]
            watch = [r for r in round_results if r["decision"] == "ğŸŸ¡ WATCH"]
            
            print(f"   âœ… æœ¬è½®å®Œæˆ: {len(round_results)} ä¸ªåˆ†æ")
            print(f"   ğŸ”´ ç«‹å³åš: {len(build_now)} | ğŸŸ¡ è§‚å¯Ÿ: {len(watch)}")
            
            # ä¼‘æ¯ä¸€ä¸‹ï¼Œé¿å…é™æµ
            time.sleep(1)
        
        # æœ€ç»ˆç»Ÿè®¡
        elapsed = time.time() - start_time
        
        self.finalize_results(elapsed, total_keywords, iterations)
        
        return self.results
    
    def finalize_results(self, elapsed: float, total_keywords: int, iterations: int):
        """æœ€ç»ˆç»“æœæ±‡æ€»"""
        print("\n" + "="*70)
        print("ğŸ‰ æ·±åº¦æŒ–æ˜å®Œæˆï¼")
        print("="*70)
        
        print(f"\nğŸ“Š æŒ–æ˜ç»Ÿè®¡:")
        print(f"   â±ï¸  æ€»è€—æ—¶: {elapsed/60:.1f} åˆ†é’Ÿ")
        print(f"   ğŸ”„  æŒ–æ˜è½®æ¬¡: {iterations}")
        print(f"   ğŸ“  åˆ†æå…³é”®è¯: {total_keywords} ä¸ª")
        
        build_now = [r for r in self.results if r["decision"] == "ğŸ”´ BUILD NOW"]
        watch = [r for r in self.results if r["decision"] == "ğŸŸ¡ WATCH"]
        drop = [r for r in self.results if r["decision"] == "âŒ DROP"]
        
        print(f"\nğŸ“ˆ è¯„åˆ†åˆ†å¸ƒ:")
        print(f"   ğŸ”´ BUILD NOW: {len(build_now)} ä¸ª")
        print(f"   ğŸŸ¡ WATCH: {len(watch)} ä¸ª")
        print(f"   âŒ DROP: {len(drop)} ä¸ª")
        
        # TOP 20 æœºä¼š
        self.results.sort(key=lambda x: x["final_score"], reverse=True)
        
        print(f"\nğŸ† TOP 20 æœºä¼šæ¸…å•:")
        print("-" * 70)
        
        for i, r in enumerate(self.results[:20], 1):
            drop_emoji = "ğŸ’" if r["é™ç»´æ‰“å‡»"] else "  "
            pain_emoji = "ğŸ˜«" if r["pain_score"] > 20 else "  "
            
            print(f"{i:2}. {drop_emoji}{pain_emoji} {r['keyword'][:45]:<45}")
            print(f"    ğŸ“Š è¯„åˆ†: {r['final_score']:>5} | {r['decision']} | {r['estimated_volume']}")
            print(f"    ğŸ¯ ç”¨æˆ·æ„å›¾: {r['user_goal']} | æ„å›¾æ¸…æ™°åº¦: {r['intent_clarity']}")
            print(f"    ğŸ”¥ éœ€æ±‚éªŒè¯: {r['demand_validation']} | {r['demand_sources'][0] if r['demand_sources'] else 'N/A'}")
            print(f"    ğŸ’¡ å»ºè®®: {r['recommendation'][:80]}")
            print()
        
        # ä¿å­˜ç»“æœ
        self.save_results()
        
        print("ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ° data_deep/ ç›®å½•")
        
    def save_results(self):
        """ä¿å­˜ç»“æœåˆ° CSV"""
        import csv
        
        if not self.results:
            return
        
        # æœ€ç»ˆç»“æœ
        csv_path = self.data_dir / "deep_dig_results.csv"
        with open(csv_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=self.results[0].keys())
            writer.writeheader()
            writer.writerows(self.results)
        
        # ç«‹å³åšæ¸…å•
        build_now = [r for r in self.results if r["decision"] == "ğŸ”´ BUILD NOW"]
        if build_now:
            build_path = self.data_dir / "build_now_list.csv"
            with open(build_path, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=build_now[0].keys())
                writer.writeheader()
                writer.writerows(build_now)
        
        # é™ç»´æ‰“å‡»æœºä¼š
        drop_attack = [r for r in self.results if r["é™ç»´æ‰“å‡»"]]
        if drop_attack:
            attack_path = self.data_dir / "drop_attack_opportunities.csv"
            with open(attack_path, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=drop_attack[0].keys())
                writer.writeheader()
                writer.writerows(drop_attack)


def main():
    parser = argparse.ArgumentParser(
        description="ğŸ’ Profit Hunter ULTIMATE - æ·±åº¦æŒ–æ˜ç‰ˆ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
    python3 deep_digger.py                    # æŒ–æ˜ 1 å°æ—¶
    python3 deep_digger.py --hours 2          # æŒ–æ˜ 2 å°æ—¶
    python3 deep_digger.py --keywords 200     # æ¯å°æ—¶åˆ†æ 200 ä¸ªè¯
        """
    )
    
    parser.add_argument("--hours", type=float, default=1,
                       help="æŒ–æ˜æ—¶é•¿ï¼ˆå°æ—¶ï¼‰ï¼Œé»˜è®¤ 1 å°æ—¶")
    parser.add_argument("--keywords", type=int, default=100,
                       help="æ¯å°æ—¶åˆ†æå…³é”®è¯æ•°é‡ï¼Œé»˜è®¤ 100")
    
    args = parser.parse_args()
    
    digger = DeepKeywordDigger()
    results = digger.run_deep_dig(
        hours=args.hours,
        keywords_per_hour=args.keywords
    )
    
    return results


if __name__ == "__main__":
    main()
