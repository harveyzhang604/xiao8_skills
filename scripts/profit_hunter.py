#!/usr/bin/env python3
"""
Profit Hunter ULTIMATE - è“æµ·å…³é”®è¯çŒå–ç³»ç»Ÿ

Usage:
    python profit_hunter.py [--trends] [--playwright] [--max 50] [--seed "word1,word2"]

Requirements:
    pip install requests pandas pytrends schedule openpyxl
    pip install playwright  # Optional, for SERP analysis
    playwright install chromium  # Optional

Author: Clawdbot Skill
Version: 3.0 ULTIMATE
"""

import argparse
import csv
import json
import os
import random
import re
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# Try imports - handle missing dependencies gracefully
try:
    import requests
except ImportError:
    requests = None

try:
    import pandas as pd
except ImportError:
    pd = None

try:
    from pytrends.request import TrendReq
except ImportError:
    TrendReq = None

try:
    from playwright.sync_api import sync_playwright
except ImportError:
    sync_playwright = None


# ============== é…ç½® ==============
CONFIG = {
    "data_dir": "data",
    "seed_words_file": "words.md",
    "thresholds": {
        "BUILD_NOW": 65,
        "WATCH": 45,
        "MIN_GPTS_RATIO": 0.03,
    },
    "serp_weak_competitors": [
        "reddit.com", "quora.com", "stackoverflow.com",
        "medium.com", "dev.to", "blogger.com", "wordpress.com"
    ],
    "serp_giants": [
        "google.com", "microsoft.com", "adobe.com",
        "canva.com", "figma.com", "notion.so"
    ],
    "pain_triggers": {
        "strong": [
            "struggling with", "how to fix", "error", "cannot",
            "doesn't work", "won't work", "failed", "broken"
        ],
        "medium": [
            "best way to", "how to", "tips for", "guide to"
        ],
        "weak": [
            "what is", "meaning of", "difference between"
        ]
    },
    "intent_signals": {
        "calculator": ["calculator", "calc", "calculation"],
        "generator": ["generator", "create", "make", "build", "generate"],
        "converter": ["converter", "convert", "conversion"],
        "checker": ["checker", "check", "verify", "validate", "test"],
        "finder": ["finder", "find", "search", "lookup", "locate"],
        "comparer": ["vs", "versus", "compare", "comparison", "alternative"],
        "planner": ["planner", "plan", "schedule", "organizer"],
        "tracker": ["tracker", "track", "monitor", "log"],
    },
    "user_intent_patterns": {
        "calculate": ["calculator", "calc", "calculation", "compute"],
        "convert": ["convert", "converter", "conversion", "transform"],
        "generate": ["generator", "create", "make", "generate", "build"],
        "check": ["check", "checker", "verify", "validate", "test"],
        "find": ["finder", "find", "search", "lookup", "locate"],
        "compare": ["compare", "comparison", "vs", "versus", "alternative"],
        "plan": ["planner", "plan", "schedule", "organize"],
        "track": ["tracker", "track", "monitor", "log"],
        "learn": ["learn", "tutorial", "guide", "how to", "explain"],
        "download": ["download", "downloads", "free"],
    }
}


# ============== æ ¸å¿ƒåŠŸèƒ½ ==============
class ProfitHunterUltimate:
    """ç»ˆæç‰ˆè“æµ·å…³é”®è¯çŒå–ç³»ç»Ÿ"""
    
    def __init__(self, config: dict = None):
        self.config = {**CONFIG, **(config or {})}
        self.data_dir = Path(self.config["data_dir"])
        self.data_dir.mkdir(exist_ok=True)
        self.results = []
        
    def load_seed_words(self) -> List[str]:
        """åŠ è½½ç§å­è¯"""
        seed_file = self.config.get("seed_words_file", "words.md")
        
        if os.path.exists(seed_file):
            with open(seed_file, 'r', encoding='utf-8') as f:
                content = f.read()
            # æå– Markdown åˆ—è¡¨ä¸­çš„è¯
            words = re.findall(r'[-*]\s*(\w+(?:\s+\w+)*)', content)
            return [w.strip().lower() for w in words if len(w) > 2]
        
        # é»˜è®¤ç§å­è¯
        return ["calculator", "generator", "converter", "checker", "finder"]
    
    def step0_google_autocomplete(self, words: List[str], max_results: int = 500) -> List[str]:
        """Step 0: Google Autocomplete æµ·é‡æŒ–è¯"""
        print("ğŸ” Step 0: Google Autocomplete æŒ–è¯...")
        
        all_keywords = set()
        modifiers = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',
                     'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',
                     'how to', 'what is', 'best', 'free', 'online', 'for', 'to']
        
        for word in words[:10]:  # é™åˆ¶ç§å­è¯æ•°é‡
            for mod in modifiers[:15]:  # é™åˆ¶ä¿®é¥°è¯æ•°é‡
                query = f"{mod} {word}"
                suggestions = self._fetch_google_suggestions(query)
                all_keywords.update(suggestions)
                if len(all_keywords) >= max_results:
                    break
            if len(all_keywords) >= max_results:
                break
        
        keywords = list(all_keywords)[:max_results]
        print(f"   ğŸ“Š æŒ–æ˜åˆ° {len(keywords)} ä¸ªå…³é”®è¯")
        
        # ä¿å­˜
        self._save_csv(f"step0_suggest_keywords.csv", 
                      [{"keyword": k} for k in keywords])
        return keywords
    
    def _fetch_google_suggestions(self, query: str) -> List[str]:
        """è·å– Google è‡ªåŠ¨è¡¥å…¨å»ºè®®"""
        if not requests:
            return []
            
        try:
            url = f"https://suggestqueries.google.com/complete/search"
            params = {
                "client": "firefox",
                "q": query,
                "hl": "en"
            }
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }
            response = requests.get(url, params=params, headers=headers, timeout=3)
            if response.status_code == 200:
                data = response.json()
                return [item[0] for item in data[1] if isinstance(item, list)]
        except Exception as e:
            pass
        return []
    
    def step1_google_trends(self, keywords: List[str], deep_dive: bool = True) -> List[Dict]:
        """Step 1: Google Trends é£™å‡è¯æ•æ‰ + äºŒçº§æ·±æŒ–"""
        print("ğŸ“ˆ Step 1: Google Trends åˆ†æ...")
        
        if not TrendReq:
            print("   âš ï¸ pytrends æœªå®‰è£…ï¼Œè·³è¿‡ Trends åˆ†æ")
            return []
        
        trends_data = []
        pytrends = TrendReq(hl='en-US', tz=360)
        
        for keyword in keywords[:50]:  # é™åˆ¶æ•°é‡
            try:
                pytrends.build_payload([keyword], timeframe='now 7-d')
                interest = pytrends.interest_over_time()
                
                if not interest.empty:
                    recent = interest[keyword].iloc[-7:].mean()
                    trends_data.append({
                        "keyword": keyword,
                        "avg_interest": recent,
                        "is_rising": recent > 50
                    })
                time.sleep(random.uniform(0.5, 1))  # é¿å…é™æµ
            except Exception as e:
                continue
        
        print(f"   ğŸ“Š åˆ†æäº† {len(trends_data)} ä¸ªå…³é”®è¯")
        
        # ä¿å­˜
        self._save_csv(f"step1_trends_deep.csv", trends_data)
        return trends_data
    
    def step2_gpts_comparison(self, keywords: List[str]) -> Dict[str, Dict]:
        """Step 2: GPTs åŸºå‡†å¯¹æ¯”ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        print("ğŸ¤– Step 2: GPTs çƒ­åº¦å¯¹æ¯”...")
        
        comparison = {}
        
        # æ¨¡æ‹Ÿ GPTs æ•°æ®ï¼ˆå®é™…éœ€è¦è°ƒç”¨ OpenAI APIï¼‰
        # è¿™é‡Œä½¿ç”¨å…³é”®è¯ç‰¹å¾æ¨¡æ‹Ÿçƒ­åº¦æ¯”
        for keyword in keywords:
            # åŸºäºå…³é”®è¯ç‰¹å¾ä¼°ç®—
            base_ratio = 0.05  # åŸºç¡€æ¯”ç‡
            
            # å·¥å…·ç±»å…³é”®è¯çƒ­åº¦æ›´é«˜
            tool_signals = ['calculator', 'generator', 'converter', 'checker', 'finder']
            if any(signal in keyword.lower() for signal in tool_signals):
                base_ratio += random.uniform(0.05, 0.20)
            
            # é•¿å°¾è¯çƒ­åº¦è¾ƒä½
            word_count = len(keyword.split())
            if word_count >= 4:
                base_ratio *= 0.5
            
            ratio = min(base_ratio, 0.5)  # æœ€é«˜ 50%
            
            comparison[keyword] = {
                "avg_ratio": round(ratio, 4),
                "gpts_count": int(ratio * 1000),  # ä¼°ç®— GPTs æ•°é‡
                "growth": random.choice([0, 5, 10, 15, 20]) if ratio > 0.05 else 0
            }
        
        print(f"   ğŸ“Š å¯¹æ¯”äº† {len(comparison)} ä¸ªå…³é”®è¯")
        
        # ä¿å­˜
        csv_data = [{"keyword": k, **v} for k, v in comparison.items()]
        self._save_csv(f"step2_gpts_comparison.csv", csv_data)
        return comparison
    
    def step3_serp_analysis(self, keywords: List[str], use_playwright: bool = False) -> Dict[str, Dict]:
        """Step 3: SERP ç«äº‰åˆ†æ"""
        print("ğŸ” Step 3: SERP ç«äº‰åˆ†æ...")
        
        serp_data = {}
        
        if use_playwright and sync_playwright:
            # ä½¿ç”¨ Playwright çœŸå®æ£€æµ‹
            serp_data = self._playwright_serp_analysis(keywords)
        else:
            # æ¨¡æ‹Ÿåˆ†æï¼ˆåŸºäºå…³é”®è¯ç‰¹å¾ï¼‰
            for keyword in keywords:
                serp_data[keyword] = self._simulate_serp_analysis(keyword)
        
        print(f"   ğŸ“Š åˆ†æäº† {len(serp_data)} ä¸ªå…³é”®è¯")
        
        # ä¿å­˜
        csv_data = [{"keyword": k, **v} for k, v in serp_data.items()]
        self._save_csv(f"step3_serp_analysis.csv", csv_data)
        return serp_data
    
    def _simulate_serp_analysis(self, keyword: str) -> Dict:
        """æ¨¡æ‹Ÿ SERP åˆ†æï¼ˆå½“ Playwright ä¸å¯ç”¨æ—¶ï¼‰"""
        keyword_lower = keyword.lower()
        
        # æ£€æµ‹æ˜¯å¦æœ‰é™ç»´æ‰“å‡»æœºä¼š
        weak_count = sum(1 for comp in self.config["serp_weak_competitors"] 
                        if comp in keyword_lower)
        giant_count = sum(1 for comp in self.config["serp_giants"] 
                         if comp in keyword_lower)
        
        if weak_count > 0 and giant_count == 0:
            competition = "ğŸŸ¢ WEAK"
            competition_score = 100
            is_drop_attack = True
        elif giant_count > 0:
            competition = "ğŸ”´ GIANT"
            competition_score = 30
            is_drop_attack = False
        else:
            competition = "ğŸŸ¡ MEDIUM"
            competition_score = 60
            is_drop_attack = False
        
        return {
            "competition": competition,
            "competition_score": competition_score,
            "é™ç»´æ‰“å‡»": is_drop_attack,
            "top_domains": random.sample([
                "reddit.com", "quora.com", "medium.com", "blogger.com",
                "wikipedia.org", "github.com", "stackoverflow.com"
            ], 3)
        }
    
    def _playwright_serp_analysis(self, keywords: List[str]) -> Dict[str, Dict]:
        """ä½¿ç”¨ Playwright è¿›è¡ŒçœŸå® SERP åˆ†æ"""
        results = {}
        
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            
            for keyword in keywords[:20]:  # é™åˆ¶æ•°é‡
                try:
                    url = f"https://www.google.com/search?q={keyword.replace(' ', '+')}"
                    page = browser.new_page()
                    page.goto(url, timeout=30000)
                    
                    # æ£€æµ‹å‰ 3 ååŸŸå
                    domains = []
                    selectors = page.locator("div.g div.yuRUbf a").first
                    
                    for i in range(3):
                        try:
                            href = selectors.nth(i).get_attribute("href")
                            if href:
                                domain = self._extract_domain(href)
                                domains.append(domain)
                        except:
                            break
                    
                    # åˆ¤æ–­ç«äº‰åº¦
                    weak_count = sum(1 for d in domains 
                                    if any(w in d for w in self.config["serp_weak_competitors"]))
                    giant_count = sum(1 for d in domains 
                                     if any(g in d for g in self.config["serp_giants"]))
                    
                    if weak_count > 0 and giant_count == 0:
                        competition = "ğŸŸ¢ WEAK"
                        competition_score = 100
                        is_drop_attack = True
                    elif giant_count > 0:
                        competition = "ğŸ”´ GIANT"
                        competition_score = 30
                        is_drop_attack = False
                    else:
                        competition = "ğŸŸ¡ MEDIUM"
                        competition_score = 60
                        is_drop_attack = False
                    
                    results[keyword] = {
                        "competition": competition,
                        "competition_score": competition_score,
                        "é™ç»´æ‰“å‡»": is_drop_attack,
                        "top_domains": domains
                    }
                    
                    page.close()
                    time.sleep(random.uniform(1, 2))  # é¿å…è¢«å°
                    
                except Exception as e:
                    results[keyword] = self._simulate_serp_analysis(keyword)
        
        return results
    
    def _extract_domain(self, url: str) -> str:
        """ä» URL æå–åŸŸå"""
        try:
            from urllib.parse import urlparse
            return urlparse(url).netloc.replace("www.", "")
        except:
            return url
    
    def step4_intent_analysis(self, keywords: List[str]) -> List[Dict]:
        """Step 4: éœ€æ±‚æ„å›¾è¯„åˆ† + ç”¨æˆ·æ„å›¾æ·±æŒ–"""
        print("ğŸ¯ Step 4: éœ€æ±‚æ„å›¾åˆ†æ...")
        
        results = []
        
        for keyword in keywords:
            keyword_lower = keyword.lower()
            signals = []
            intent_score = 70  # åŸºç¡€åˆ†
            
            # æ£€æµ‹ä¿¡å·è¯
            for signal_type, trigger_words in self.config["intent_signals"].items():
                if any(tw in keyword_lower for tw in trigger_words):
                    signals.append(signal_type)
                    if signal_type in ["calculator", "generator", "converter"]:
                        intent_score += 30
                    elif signal_type in ["checker", "finder"]:
                        intent_score += 25
                    elif signal_type == "comparer":
                        intent_score += 20
            
            # æ£€æµ‹ç—›ç‚¹
            pain_score = 0
            for level, triggers in self.config["pain_triggers"].items():
                if any(t in keyword_lower for t in triggers):
                    pain_score += 40 if level == "strong" else 20
            
            if pain_score > 0:
                intent_score += pain_score
                signals.append("pain_point")
            
            # é•¿å°¾è¯åŠ åˆ†
            word_count = len(keyword.split())
            if 2 <= word_count <= 4:
                intent_score += 15
                signals.append("long_tail")
            
            # ç”¨æˆ·æ„å›¾æ·±æŒ–
            user_intent, user_goal, intent_clarity = self._analyze_user_intent(keyword, signals)
            
            results.append({
                "keyword": keyword,
                "signals": ",".join(signals) if signals else "general",
                "intent_score": min(intent_score, 100),
                "user_intent": user_intent,
                "user_goal": user_goal,
                "intent_clarity": intent_clarity
            })
        
        print(f"   ğŸ“Š åˆ†æäº† {len(results)} ä¸ªå…³é”®è¯")
        return results
    
    def _analyze_user_intent(self, keyword: str, signals: List[str]) -> Tuple[str, str, str]:
        """ç”¨æˆ·æ„å›¾æ·±æŒ–åˆ†æ"""
        keyword_lower = keyword.lower()
        
        # æ£€æµ‹ç”¨æˆ·çœŸæ­£æƒ³åšä»€ä¹ˆ
        detected_intents = []
        for intent, patterns in self.config["user_intent_patterns"].items():
            if any(p in keyword_lower for p in patterns):
                detected_intents.append(intent)
        
        if not detected_intents:
            detected_intents = ["explore"]
        
        # è®¡ç®—æ„å›¾æ¸…æ™°åº¦
        if len(detected_intents) == 1 and detected_intents[0] != "explore":
            clarity = "é«˜"
        elif len(detected_intents) <= 2:
            clarity = "ä¸­"
        else:
            clarity = "ä½"
        
        # ç”Ÿæˆç”¨æˆ·ç›®æ ‡æè¿°
        intent_str = ",".join(detected_intents)
        
        if len(detected_intents) == 1:
            goal_map = {
                "calculate": "è®¡ç®—æŸä¸ªæ•°å€¼",
                "convert": "è½¬æ¢å•ä½æˆ–æ ¼å¼",
                "generate": "è‡ªåŠ¨ç”Ÿæˆå†…å®¹",
                "check": "éªŒè¯æˆ–æ£€æŸ¥æŸäº‹",
                "find": "æŸ¥æ‰¾ä¿¡æ¯",
                "compare": "æ¯”è¾ƒé€‰é¡¹",
                "plan": "åˆ¶å®šè®¡åˆ’",
                "track": "è¿½è¸ªæ•°æ®",
                "learn": "å­¦ä¹ äº†è§£",
                "download": "ä¸‹è½½èµ„æº",
                "explore": "æµè§ˆäº†è§£"
            }
            user_goal = goal_map.get(detected_intents[0], "å®ŒæˆæŸé¡¹ä»»åŠ¡")
        else:
            user_goal = f"å¤åˆéœ€æ±‚ï¼š{', '.join(detected_intents)}"
        
        return intent_str, user_goal, clarity
    
    def step5_calculate_scores(self, keywords: List[str], 
                               trends_data: List[Dict], 
                               gpts_comparison: Dict[str, Dict],
                               serp_data: Dict[str, Dict],
                               intent_data: List[Dict]) -> List[Dict]:
        """Step 5: ç»ˆæè¯„åˆ†"""
        print("ğŸ† Step 5: è®¡ç®—æœ€ç»ˆè¯„åˆ†...")
        
        # è½¬æ¢ä¸ºå­—å…¸ä¾¿äºæŸ¥è¯¢
        trends_dict = {d["keyword"]: d for d in trends_data}
        intent_dict = {d["keyword"]: d for d in intent_data}
        
        final_results = []
        
        for keyword in keywords:
            # è·å–å„é¡¹æ•°æ®
            trend_info = trends_dict.get(keyword, {"avg_interest": 0, "is_rising": False})
            gpts_info = gpts_comparison.get(keyword, {"avg_ratio": 0, "growth": 0})
            serp_info = serp_data.get(keyword, {
                "competition_score": 60,
                "é™ç»´æ‰“å‡»": False
            })
            intent_info = intent_dict.get(keyword, {
                "intent_score": 70,
                "user_intent": "explore",
                "user_goal": "æµè§ˆäº†è§£",
                "intent_clarity": "ä¸­"
            })
            
            # è®¡ç®—å„é¡¹åˆ†æ•°
            # Trend Score
            if gpts_info["avg_ratio"] >= 0.20 and gpts_info["growth"] > 0:
                trend_score = 100
            elif gpts_info["avg_ratio"] >= 0.10 and gpts_info["growth"] > 5:
                trend_score = 85
            elif gpts_info["avg_ratio"] >= 0.03:
                trend_score = 70
            else:
                trend_score = 50
            
            # Intent Score
            intent_score = intent_info["intent_score"]
            
            # Competition Score
            competition_score = serp_info["competition_score"]
            
            # Buildability Score
            keyword_lower = keyword.lower()
            if any(t in keyword_lower for t in ["calculator", "generator", "converter"]):
                build_score = 100
            elif any(t in keyword_lower for t in ["online", "free"]):
                build_score = 85
            else:
                build_score = 70
            
            # æœ€ç»ˆè¯„åˆ†ï¼ˆåŠ æƒï¼‰
            final_score = (
                trend_score * 0.25 +
                intent_score * 0.35 +
                competition_score * 0.25 +
                build_score * 0.15
            )
            
            # å†³ç­–
            thresholds = self.config["thresholds"]
            if final_score >= thresholds["BUILD_NOW"]:
                decision = "ğŸ”´ BUILD NOW"
            elif final_score >= thresholds["WATCH"]:
                decision = "ğŸŸ¡ WATCH"
            else:
                decision = "âŒ DROP"
            
            result = {
                "keyword": keyword,
                "final_score": round(final_score, 1),
                "decision": decision,
                "avg_ratio": f"{gpts_info['avg_ratio']*100:.1f}%",
                "user_intent": intent_info["user_intent"],
                "user_goal": intent_info["user_goal"],
                "intent_clarity": intent_info["intent_clarity"],
                "competition": serp_info["competition"],
                "é™ç»´æ‰“å‡»": serp_info["é™ç»´æ‰“å‡»"],
                "intent_score": intent_info["intent_score"],
                "signals": intent_info["signals"]
            }
            
            final_results.append(result)
        
        # æŒ‰è¯„åˆ†æ’åº
        final_results.sort(key=lambda x: x["final_score"], reverse=True)
        
        print(f"   ğŸ“Š è¯„åˆ†å®Œæˆï¼Œå…± {len(final_results)} ä¸ªå…³é”®è¯")
        return final_results
    
    def step6_output_results(self, results: List[Dict]):
        """Step 6: è¾“å‡ºæœ€ç»ˆç»“æœ"""
        print("\n" + "="*60)
        print("ğŸ‰ åˆ†æå®Œæˆï¼")
        print("="*60)
        
        # ç»Ÿè®¡
        build_now = [r for r in results if r["decision"] == "ğŸ”´ BUILD NOW"]
        watch = [r for r in results if r["decision"] == "ğŸŸ¡ WATCH"]
        drop = [r for r in results if r["decision"] == "âŒ DROP"]
        
        print(f"\nğŸ“Š ç»Ÿè®¡:")
        print(f"   ğŸ”´ ç«‹å³åš: {len(build_now)} ä¸ª")
        print(f"   ğŸŸ¡ è§‚å¯Ÿ: {len(watch)} ä¸ª")
        print(f"   âŒ æ”¾å¼ƒ: {len(drop)} ä¸ª")
        
        # æ˜¾ç¤º Top 10
        print(f"\nğŸ† TOP 10 æœºä¼š:")
        print("-" * 60)
        
        for i, r in enumerate(results[:10], 1):
            drop_emoji = "ğŸ’" if r["é™ç»´æ‰“å‡»"] else "  "
            print(f"{i:2}. {drop_emoji} {r['keyword'][:40]:<40} | è¯„åˆ†: {r['final_score']:>5} | {r['decision']}")
            print(f"    ğŸ“Œ ç”¨æˆ·æ„å›¾: {r['user_goal']} | æ„å›¾æ¸…æ™°åº¦: {r['intent_clarity']}")
            print(f"    ğŸ“Š GPTs çƒ­åº¦: {r['avg_ratio']} | ç«äº‰åº¦: {r['competition']}")
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        self._save_csv("ultimate_final_results.csv", results)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ° data/ ç›®å½•:")
        print(f"   - ultimate_final_results.csv (æœ€ç»ˆç»“æœ)")
        print(f"   - step0_suggest_keywords.csv")
        print(f"   - step1_trends_deep.csv")
        print(f"   - step2_gpts_comparison.csv")
        print(f"   - step3_serp_analysis.csv")
        
        return results
    
    def _save_csv(self, filename: str, data: List[Dict]):
        """ä¿å­˜ CSV æ–‡ä»¶"""
        filepath = self.data_dir / filename
        if data:
            df = pd.DataFrame(data)
            df.to_csv(filepath, index=False, encoding='utf-8')
    
    def run(self, use_trends: bool = False, use_playwright: bool = False, 
            max_keywords: int = 500, seed_words: str = None):
        """è¿è¡Œå®Œæ•´æµç¨‹"""
        print("\n" + "="*60)
        print("ğŸ’ Profit Hunter ULTIMATE v3.0")
        print("="*60)
        print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("-" * 60)
        
        # Step 0: åŠ è½½ç§å­è¯å¹¶æŒ–è¯
        if seed_words:
            words = [w.strip() for w in seed_words.split(",")]
        else:
            words = self.load_seed_words()
        
        if not words:
            words = self.load_seed_words()
        
        print(f"ğŸ“ ä½¿ç”¨ç§å­è¯: {', '.join(words[:5])}...")
        keywords = self.step0_google_autocomplete(words, max_keywords)
        
        # Step 1: Google Trendsï¼ˆå¯é€‰ï¼‰
        trends_data = []
        if use_trends:
            trends_data = self.step1_google_trends(keywords)
        
        # Step 2: GPTs å¯¹æ¯”
        gpts_comparison = self.step2_gpts_comparison(keywords)
        
        # Step 3: SERP åˆ†æ
        serp_data = self.step3_serp_analysis(keywords, use_playwright)
        
        # Step 4: æ„å›¾åˆ†æ
        intent_data = self.step4_intent_analysis(keywords)
        
        # Step 5: è®¡ç®—æœ€ç»ˆè¯„åˆ†
        results = self.step5_calculate_scores(
            keywords, trends_data, gpts_comparison, serp_data, intent_data
        )
        
        # Step 6: è¾“å‡ºç»“æœ
        self.step6_output_results(results)
        
        return results


# ============== ä¸»ç¨‹åº ==============
def main():
    parser = argparse.ArgumentParser(
        description="ğŸ’ Profit Hunter ULTIMATE - ç»ˆæç‰ˆè“æµ·å…³é”®è¯çŒå–ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
    python profit_hunter.py                           # å¿«é€Ÿæ¨¡å¼
    python profit_hunter.py --trends                  # åŒ…å« Trends åˆ†æ
    python profit_hunter.py --trends --playwright     # ç»ˆæç‰ˆï¼ˆPlaywrightï¼‰
    python profit_hunter.py --max 100 --seed "ai,ml"  # è‡ªå®šä¹‰å‚æ•°
        """
    )
    
    parser.add_argument("--trends", action="store_true",
                       help="å¯ç”¨ Google Trends åˆ†æ")
    parser.add_argument("--playwright", action="store_true",
                       help="å¯ç”¨ Playwright SERP åˆ†æï¼ˆéœ€è¦å®‰è£… playwrightï¼‰")
    parser.add_argument("--max", type=int, default=500,
                       help="æœ€å¤§å…³é”®è¯æ•°é‡ (é»˜è®¤: 500)")
    parser.add_argument("--seed", type=str, default=None,
                       help="ç§å­è¯ï¼Œé€—å·åˆ†éš” (ä¾‹å¦‚: 'ai,ml,python')")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥ä¾èµ–
    missing_deps = []
    if not requests:
        missing_deps.append("requests")
    if not pd:
        missing_deps.append("pandas")
    if args.trends and not TrendReq:
        missing_deps.append("pytrends")
    if args.playwright and not sync_playwright:
        missing_deps.append("playwright")
    
    if missing_deps:
        print(f"âš ï¸  ç¼ºå°‘ä¾èµ–: {', '.join(missing_deps)}")
        print("   å®‰è£…å‘½ä»¤: pip install requests pandas pytrends schedule openpyxl")
        if args.playwright:
            print("   Playwright: pip install playwright && playwright install chromium")
        print()
    
    # è¿è¡Œ
    hunter = ProfitHunterUltimate()
    results = hunter.run(
        use_trends=args.trends,
        use_playwright=args.playwright,
        max_keywords=args.max,
        seed_words=args.seed
    )
    
    # è¿”å›åˆé€‚çš„é€€å‡ºç 
    build_now_count = sum(1 for r in results if r["decision"] == "ğŸ”´ BUILD NOW")
    sys.exit(0 if build_now_count > 0 else 1)


if __name__ == "__main__":
    main()
